{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c400738a",
   "metadata": {},
   "source": [
    "# Projet NLP : NER avec CamemBERT (Transformers)\n",
    "\n",
    "## Reconnaissance des Entités Nommées en français avec Fine-tuning de Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7272ba87",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### 1.1 Contexte\n",
    "\n",
    "Ce notebook explore l'utilisation de **CamemBERT**, un modèle Transformer pré-entraîné sur des corpus français massifs, pour la tâche de Reconnaissance des Entités Nommées (NER).\n",
    "\n",
    "### 1.2 Approche Transformers vs CRF\n",
    "\n",
    "**CRF (notebook précédent) :**\n",
    "- Modèle séquentiel classique basé sur des features manuelles\n",
    "- Entraînement from scratch sur le corpus\n",
    "- Rapide, léger, ne nécessite pas de GPU\n",
    "- Performance limitée par les features extraites\n",
    "\n",
    "**CamemBERT (ce notebook) :**\n",
    "- Modèle Transformer pré-entraîné sur 138 GB de texte français\n",
    "- Comprend le contexte bidirectionnel profond\n",
    "- Fine-tuning sur notre tâche spécifique\n",
    "- Meilleure performance attendue (+10-20% F1)\n",
    "- Nécessite plus de ressources (GPU recommandé)\n",
    "\n",
    "### 1.3 Dataset\n",
    "\n",
    "MultiCoNER v2 (français) : 68 types d'entités nommées, format BIO\n",
    "- Train : 16,548 phrases\n",
    "- Dev : 857 phrases\n",
    "- Test : 249,786 phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44c187",
   "metadata": {},
   "source": [
    "## 2. Installation et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893864e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des dépendances (à exécuter une seule fois)\n",
    "# !pip install transformers torch datasets seqeval accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a3c0f",
   "metadata": {},
   "source": [
    "## Colab (recommandé)\n",
    "\n",
    "1. Activer GPU : Runtime → Change runtime type → GPU\n",
    "2. Uploader `data.zip` (contenant `data/fr_train.conll`, `data/fr_dev.conll`, `data/fr_test.conll`)\n",
    "3. Exécuter la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db213f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détection Colab + téléchargement automatique des données depuis GitHub\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "BASE_DIR = Path(\"/content\") if IN_COLAB else Path(\"..\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Colab détecté. Téléchargement des données depuis GitHub...\")\n",
    "    \n",
    "    # Créer le dossier data\n",
    "    data_dir = BASE_DIR / \"data\"\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # URLs GitHub des fichiers CoNLL (raw content)\n",
    "    github_raw_url = \"https://raw.githubusercontent.com/Badji-M/NLP/main/data\"\n",
    "    files_to_download = [\"fr_train.conll\", \"fr_dev.conll\", \"fr_test.conll\"]\n",
    "    \n",
    "    for filename in files_to_download:\n",
    "        url = f\"{github_raw_url}/{filename}\"\n",
    "        filepath = data_dir / filename\n",
    "        print(f\"Téléchargement {filename}...\", end=\" \")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filepath)\n",
    "            print(f\"✓ ({filepath.stat().st_size / (1024*1024):.1f} MB)\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Erreur : {e}\")\n",
    "    \n",
    "    print(\"\\nDonnées téléchargées dans\", data_dir)\n",
    "\n",
    "print(\"BASE_DIR =\", BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports système et manipulation de données\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Transformers et PyTorch\n",
    "import torch\n",
    "from transformers import (\n",
    "    CamembertForTokenClassification,\n",
    "    CamembertTokenizerFast,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Métriques\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# Configuration\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Vérification GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device utilisé : {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU : {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Attention : CPU détecté. L'entraînement sera lent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7e92e",
   "metadata": {},
   "source": [
    "## 3. Chargement des données\n",
    "\n",
    "### 3.1 Configuration des chemins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = Path(\"..\") / \"data\"\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "train_path = DATA_DIR / \"fr_train.conll\"\n",
    "dev_path   = DATA_DIR / \"fr_dev.conll\"\n",
    "test_path  = DATA_DIR / \"fr_test.conll\"\n",
    "\n",
    "# Vérification\n",
    "for p in [train_path, dev_path, test_path]:\n",
    "    print(f\"{p.name:20s} -> {p.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa1ff7",
   "metadata": {},
   "source": [
    "### 3.2 Fonction de lecture CoNLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll(path):\n",
    "    \"\"\"\n",
    "    Lit un fichier CoNLL et retourne les phrases et labels.\n",
    "    \n",
    "    Format CoNLL : token TAB _ TAB _ TAB label, phrases séparées par lignes vides\n",
    "    Format réel : elle _ _ O\n",
    "                  porte _ _ O\n",
    "                  susan _ _ B-Artist\n",
    "    \n",
    "    Returns:\n",
    "        sentences: List[List[str]] - liste de phrases (liste de tokens)\n",
    "        labels: List[List[str]] - liste de labels BIO correspondants\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    \n",
    "    current_sentence = []\n",
    "    current_labels = []\n",
    "    \n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Ignorer les lignes vides et les commentaires\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                if current_sentence:\n",
    "                    sentences.append(current_sentence)\n",
    "                    labels.append(current_labels)\n",
    "                    current_sentence = []\n",
    "                    current_labels = []\n",
    "                continue\n",
    "            \n",
    "            # Extraction token et label (format : token TAB _ TAB _ TAB label)\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 4:\n",
    "                token = parts[0]\n",
    "                label = parts[3]\n",
    "                \n",
    "                current_sentence.append(token)\n",
    "                current_labels.append(label)\n",
    "    \n",
    "    # Dernière phrase si le fichier ne se termine pas par une ligne vide\n",
    "    if current_sentence:\n",
    "        sentences.append(current_sentence)\n",
    "        labels.append(current_labels)\n",
    "    \n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50ca9ea",
   "metadata": {},
   "source": [
    "### 3.3 Chargement des trois ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chargement des données...\")\n",
    "train_sentences, train_labels = read_conll(train_path)\n",
    "dev_sentences, dev_labels = read_conll(dev_path)\n",
    "test_sentences, test_labels = read_conll(test_path)\n",
    "\n",
    "print(\"\\nStatistiques :\")\n",
    "print(f\"Train : {len(train_sentences):6,} phrases, {sum(len(s) for s in train_sentences):8,} tokens\")\n",
    "print(f\"Dev   : {len(dev_sentences):6,} phrases, {sum(len(s) for s in dev_sentences):8,} tokens\")\n",
    "print(f\"Test  : {len(test_sentences):6,} phrases, {sum(len(s) for s in test_sentences):8,} tokens\")\n",
    "\n",
    "print(\"\\nExemple (première phrase train) :\")\n",
    "print(f\"Tokens : {train_sentences[0][:10]}...\")\n",
    "print(f\"Labels : {train_labels[0][:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75e530",
   "metadata": {},
   "source": [
    "## 4. Préparation des labels\n",
    "\n",
    "### 4.1 Construction du mapping label-to-id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération de tous les labels uniques\n",
    "all_labels = set()\n",
    "for labels in train_labels + dev_labels + test_labels:\n",
    "    all_labels.update(labels)\n",
    "\n",
    "# Tri pour reproductibilité\n",
    "unique_labels = sorted(list(all_labels))\n",
    "\n",
    "# Création des mappings\n",
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "num_labels = len(unique_labels)\n",
    "\n",
    "print(f\"Nombre de labels uniques : {num_labels}\")\n",
    "print(f\"\\nPremiers labels : {unique_labels[:10]}\")\n",
    "print(f\"Derniers labels : {unique_labels[-10:]}\")\n",
    "\n",
    "# Statistiques sur les entités\n",
    "entity_labels = [l for l in unique_labels if l.startswith('B-')]\n",
    "print(f\"\\nNombre de types d'entités (B-) : {len(entity_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d57c15",
   "metadata": {},
   "source": [
    "### 4.2 Conversion en format Hugging Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(sentences, labels):\n",
    "    \"\"\"\n",
    "    Convertit les données au format Hugging Face Dataset.\n",
    "    \n",
    "    Args:\n",
    "        sentences: List[List[str]]\n",
    "        labels: List[List[str]]\n",
    "    \n",
    "    Returns:\n",
    "        Dataset avec colonnes 'tokens' et 'ner_tags'\n",
    "    \"\"\"\n",
    "    # Conversion des labels en IDs\n",
    "    ner_tags = [[label2id[label] for label in sent_labels] for sent_labels in labels]\n",
    "    \n",
    "    return Dataset.from_dict({\n",
    "        \"tokens\": sentences,\n",
    "        \"ner_tags\": ner_tags\n",
    "    })\n",
    "\n",
    "# Création des datasets\n",
    "train_dataset = create_dataset(train_sentences, train_labels)\n",
    "dev_dataset = create_dataset(dev_sentences, dev_labels)\n",
    "test_dataset = create_dataset(test_sentences, test_labels)\n",
    "\n",
    "# Création du DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": dev_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "print(dataset)\n",
    "print(\"\\nExemple du dataset train :\")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c65a3ae",
   "metadata": {},
   "source": [
    "## 5. Tokenization avec CamemBERT\n",
    "\n",
    "### 5.1 Chargement du tokenizer\n",
    "\n",
    "CamemBERT utilise un tokenizer SentencePiece (subword tokenization) qui découpe les mots en sous-unités. Cela nécessite un alignement spécial avec les labels NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"camembert-base\"\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(model_checkpoint)\n",
    "\n",
    "print(f\"Tokenizer chargé : {model_checkpoint}\")\n",
    "print(f\"Vocabulaire : {tokenizer.vocab_size:,} tokens\")\n",
    "\n",
    "# Test du tokenizer\n",
    "exemple = \"La romancière américaine Susan Sontag\"\n",
    "tokens = tokenizer.tokenize(exemple)\n",
    "print(f\"\\nExemple de tokenization :\")\n",
    "print(f\"Texte  : {exemple}\")\n",
    "print(f\"Tokens : {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b56a9b",
   "metadata": {},
   "source": [
    "### 5.2 Fonction de tokenization et alignement des labels\n",
    "\n",
    "Problématique : Un mot peut être découpé en plusieurs subwords. Il faut aligner les labels NER correctement.\n",
    "\n",
    "Stratégie : \n",
    "- Le premier subword d'un mot reçoit le label du mot\n",
    "- Les subwords suivants reçoivent -100 (ignorés dans le calcul de la loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017e044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    \"\"\"\n",
    "    Tokenize les mots et aligne les labels NER avec les subwords.\n",
    "    \n",
    "    Args:\n",
    "        examples: batch du dataset avec 'tokens' et 'ner_tags'\n",
    "    \n",
    "    Returns:\n",
    "        dict avec input_ids, attention_mask, labels alignés\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=False  # Le DataCollator gérera le padding\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for i, label_ids in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids_aligned = []\n",
    "        \n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            # Tokens spéciaux (CLS, SEP, PAD) -> -100\n",
    "            if word_idx is None:\n",
    "                label_ids_aligned.append(-100)\n",
    "            # Début d'un nouveau mot -> label du mot\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids_aligned.append(label_ids[word_idx])\n",
    "            # Continuation d'un mot (subword) -> -100\n",
    "            else:\n",
    "                label_ids_aligned.append(-100)\n",
    "            \n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        labels.append(label_ids_aligned)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Application de la tokenization\n",
    "print(\"Tokenization des datasets...\")\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "print(\"\\nDatasets tokenizés :\")\n",
    "print(tokenized_dataset)\n",
    "print(\"\\nExemple tokenizé :\")\n",
    "print(f\"input_ids : {tokenized_dataset['train'][0]['input_ids'][:20]}...\")\n",
    "print(f\"labels    : {tokenized_dataset['train'][0]['labels'][:20]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30173fc2",
   "metadata": {},
   "source": [
    "## 6. Chargement et configuration du modèle\n",
    "\n",
    "### 6.1 Chargement de CamemBERT pré-entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee2495",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chargement du modèle CamemBERT...\")\n",
    "print(\"(Première exécution : téléchargement de ~440 MB)\\n\")\n",
    "\n",
    "model = CamembertForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Déplacement vers GPU si disponible\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Modèle chargé sur {device}\")\n",
    "print(f\"Nombre de paramètres : {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Paramètres entraînables : {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154f6c0c",
   "metadata": {},
   "source": [
    "### 6.2 Data Collator\n",
    "\n",
    "Le Data Collator gère le padding dynamique des batches pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae9efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "print(\"Data Collator configuré (padding dynamique activé)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed9cd9",
   "metadata": {},
   "source": [
    "## 7. Métriques d'évaluation\n",
    "\n",
    "### 7.1 Fonction de calcul des métriques\n",
    "\n",
    "Utilisation de seqeval pour respecter les contraintes BIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0634dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Calcule les métriques NER (precision, recall, F1) avec seqeval.\n",
    "    \n",
    "    Args:\n",
    "        eval_pred: tuple (predictions, labels)\n",
    "    \n",
    "    Returns:\n",
    "        dict avec precision, recall, f1, accuracy\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Predictions = logits -> argmax pour obtenir les classes\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    # Conversion en labels texte, en ignorant les -100\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        true_labels_seq = []\n",
    "        pred_labels_seq = []\n",
    "        \n",
    "        for pred_id, label_id in zip(prediction, label):\n",
    "            if label_id != -100:  # Ignorer les tokens spéciaux\n",
    "                true_labels_seq.append(id2label[label_id])\n",
    "                pred_labels_seq.append(id2label[pred_id])\n",
    "        \n",
    "        true_labels.append(true_labels_seq)\n",
    "        pred_labels.append(pred_labels_seq)\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, pred_labels),\n",
    "        \"recall\": recall_score(true_labels, pred_labels),\n",
    "        \"f1\": f1_score(true_labels, pred_labels)\n",
    "    }\n",
    "\n",
    "print(\"Fonction de métriques configurée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a726d994",
   "metadata": {},
   "source": [
    "## 8. Configuration de l'entraînement\n",
    "\n",
    "### 8.1 Hyperparamètres\n",
    "\n",
    "Configuration optimale pour le fine-tuning de CamemBERT (modèle français) sur NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464c28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dossier de sortie\n",
    "output_dir = BASE_DIR / \"models\" / \"camembert_ner\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(output_dir),\n",
    "    \n",
    "    # Hyperparamètres d'entraînement\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    \n",
    "    # Évaluation\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    \n",
    "    # Logging\n",
    "    logging_dir=str(output_dir / \"logs\"),\n",
    "    logging_steps=50,\n",
    "    \n",
    "    # Optimisations\n",
    "    fp16=torch.cuda.is_available(),  # Mixed precision si GPU\n",
    "    dataloader_num_workers=4,\n",
    "    \n",
    "    # Autres\n",
    "    seed=42,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "print(\"Configuration d'entraînement :\")\n",
    "print(f\"  Epochs           : {training_args.num_train_epochs}\")\n",
    "print(f\"  Batch size train : {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Learning rate    : {training_args.learning_rate}\")\n",
    "print(f\"  FP16 (GPU)       : {training_args.fp16}\")\n",
    "print(f\"  Output dir       : {training_args.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808db519",
   "metadata": {},
   "source": [
    "### 8.2 Initialisation du Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96492625",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"Trainer initialisé\")\n",
    "print(f\"Nombre de steps d'entraînement : {len(tokenized_dataset['train']) // training_args.per_device_train_batch_size * training_args.num_train_epochs:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ceb77",
   "metadata": {},
   "source": [
    "## 9. Fine-tuning du modèle\n",
    "\n",
    "### 9.1 Lancement de l'entraînement\n",
    "\n",
    "Durée estimée : \n",
    "- Avec GPU : 30-60 minutes\n",
    "- Avec CPU : 4-8 heures (non recommandé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae87a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DÉBUT DU FINE-TUNING\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Device : {device}\")\n",
    "print(f\"Début : {time.strftime('%H:%M:%S')}\")\n",
    "print()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Entraînement\n",
    "train_result = trainer.train()\n",
    "\n",
    "# Temps total\n",
    "total_time = time.time() - start_time\n",
    "hours = int(total_time // 3600)\n",
    "minutes = int((total_time % 3600) // 60)\n",
    "seconds = int(total_time % 60)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"FIN DE L'ENTRAÎNEMENT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Durée totale : {hours:02d}h {minutes:02d}m {seconds:02d}s\")\n",
    "print(f\"Fin : {time.strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778b940",
   "metadata": {},
   "source": [
    "### 9.2 Métriques d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abc8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des métriques\n",
    "train_metrics = train_result.metrics\n",
    "\n",
    "print(\"Métriques d'entraînement :\")\n",
    "print(f\"  Training loss    : {train_metrics['train_loss']:.4f}\")\n",
    "print(f\"  Training runtime : {train_metrics['train_runtime']:.2f}s\")\n",
    "print(f\"  Samples/second   : {train_metrics['train_samples_per_second']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1da7df",
   "metadata": {},
   "source": [
    "## 10. Évaluation sur le dev set\n",
    "\n",
    "### 10.1 Prédictions et métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ÉVALUATION SUR DEV SET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Évaluation\n",
    "dev_results = trainer.evaluate()\n",
    "\n",
    "print(f\"\\nMétriques globales (dev) :\")\n",
    "print(f\"  Precision : {dev_results['eval_precision']:.4f}\")\n",
    "print(f\"  Recall    : {dev_results['eval_recall']:.4f}\")\n",
    "print(f\"  F1-score  : {dev_results['eval_f1']:.4f}\")\n",
    "print(f\"  Loss      : {dev_results['eval_loss']:.4f}\")\n",
    "\n",
    "# Sauvegarde des résultats\n",
    "dev_f1 = dev_results['eval_f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2d6da",
   "metadata": {},
   "source": [
    "### 10.2 Rapport détaillé par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb956697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions détaillées\n",
    "predictions_output = trainer.predict(tokenized_dataset[\"validation\"])\n",
    "predictions = np.argmax(predictions_output.predictions, axis=2)\n",
    "\n",
    "# Conversion en labels\n",
    "true_labels_dev = []\n",
    "pred_labels_dev = []\n",
    "\n",
    "for prediction, label in zip(predictions, predictions_output.label_ids):\n",
    "    true_seq = []\n",
    "    pred_seq = []\n",
    "    for pred_id, label_id in zip(prediction, label):\n",
    "        if label_id != -100:\n",
    "            true_seq.append(id2label[label_id])\n",
    "            pred_seq.append(id2label[pred_id])\n",
    "    true_labels_dev.append(true_seq)\n",
    "    pred_labels_dev.append(pred_seq)\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RAPPORT DE CLASSIFICATION DÉTAILLÉ (DEV)\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(true_labels_dev, pred_labels_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e5deaa",
   "metadata": {},
   "source": [
    "### 10.3 Analyse des meilleures et pires classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du rapport par classe\n",
    "report_dict = classification_report(true_labels_dev, pred_labels_dev, output_dict=True)\n",
    "\n",
    "# Extraction des F1 par classe (hors moyennes)\n",
    "classes_f1 = {\n",
    "    k: v['f1-score'] \n",
    "    for k, v in report_dict.items() \n",
    "    if k not in ['micro avg', 'macro avg', 'weighted avg'] and k != 'O'\n",
    "}\n",
    "\n",
    "# Top 10 meilleures classes\n",
    "top10_best = sorted(classes_f1.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(\"Top 10 classes les mieux prédites :\")\n",
    "for label, f1_val in top10_best:\n",
    "    support = report_dict[label]['support']\n",
    "    print(f\"  {label:35s} : F1={f1_val:.3f}  (support={support:4d})\")\n",
    "\n",
    "# Top 10 pires classes\n",
    "top10_worst = sorted(classes_f1.items(), key=lambda x: x[1])[:10]\n",
    "print(\"\\nTop 10 classes les plus difficiles :\")\n",
    "for label, f1_val in top10_worst:\n",
    "    support = report_dict[label]['support']\n",
    "    print(f\"  {label:35s} : F1={f1_val:.3f}  (support={support:4d})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bdc6e8",
   "metadata": {},
   "source": [
    "## 11. Évaluation sur le test set\n",
    "\n",
    "### 11.1 Prédictions finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf67d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"ÉVALUATION FINALE SUR TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Évaluation sur test\n",
    "test_results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "\n",
    "print(f\"\\nMétriques globales (test) :\")\n",
    "print(f\"  Precision : {test_results['eval_precision']:.4f}\")\n",
    "print(f\"  Recall    : {test_results['eval_recall']:.4f}\")\n",
    "print(f\"  F1-score  : {test_results['eval_f1']:.4f}\")\n",
    "print(f\"  Loss      : {test_results['eval_loss']:.4f}\")\n",
    "\n",
    "# Sauvegarde\n",
    "test_f1 = test_results['eval_f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71a35d",
   "metadata": {},
   "source": [
    "### 11.2 Comparaison Dev vs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ffebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau comparatif\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Split': ['Dev', 'Test'],\n",
    "    'Precision': [dev_results['eval_precision'], test_results['eval_precision']],\n",
    "    'Recall': [dev_results['eval_recall'], test_results['eval_recall']],\n",
    "    'F1-score': [dev_results['eval_f1'], test_results['eval_f1']]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPARAISON DEV vs TEST\")\n",
    "print(\"=\" * 70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualisation\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, comparison_df['Precision'], width, label='Precision', color='#3498db')\n",
    "ax.bar(x, comparison_df['Recall'], width, label='Recall', color='#e74c3c')\n",
    "ax.bar(x + width, comparison_df['F1-score'], width, label='F1-score', color='#2ecc71')\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Performance CamemBERT : Dev vs Test', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df['Split'])\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Annotations\n",
    "for i, (prec, rec, f1) in enumerate(zip(comparison_df['Precision'], comparison_df['Recall'], comparison_df['F1-score'])):\n",
    "    ax.text(i - width, prec + 0.02, f'{prec:.3f}', ha='center', fontsize=9)\n",
    "    ax.text(i, rec + 0.02, f'{rec:.3f}', ha='center', fontsize=9)\n",
    "    ax.text(i + width, f1 + 0.02, f'{f1:.3f}', ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4991f6f1",
   "metadata": {},
   "source": [
    "## 12. Sauvegarde du modèle final\n",
    "\n",
    "### 12.1 Sauvegarde complète"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle et du tokenizer\n",
    "final_model_dir = BASE_DIR / \"models\" / \"camembert_ner_final\"\n",
    "final_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Sauvegarde du modèle final...\")\n",
    "trainer.save_model(str(final_model_dir))\n",
    "tokenizer.save_pretrained(str(final_model_dir))\n",
    "\n",
    "print(f\"Modèle sauvegardé dans : {final_model_dir}\")\n",
    "\n",
    "# Sauvegarde des métadonnées\n",
    "metadata = {\n",
    "    \"model_name\": \"CamemBERT-base fine-tuned for NER\",\n",
    "    \"model_checkpoint\": model_checkpoint,\n",
    "    \"dataset\": \"MultiCoNER v2 (français)\",\n",
    "    \"num_labels\": num_labels,\n",
    "    \"num_train_samples\": len(train_sentences),\n",
    "    \"num_dev_samples\": len(dev_sentences),\n",
    "    \"num_test_samples\": len(test_sentences),\n",
    "    \"training_args\": {\n",
    "        \"epochs\": training_args.num_train_epochs,\n",
    "        \"batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"learning_rate\": training_args.learning_rate\n",
    "    },\n",
    "    \"results\": {\n",
    "        \"dev_precision\": float(dev_results['eval_precision']),\n",
    "        \"dev_recall\": float(dev_results['eval_recall']),\n",
    "        \"dev_f1\": float(dev_results['eval_f1']),\n",
    "        \"test_precision\": float(test_results['eval_precision']),\n",
    "        \"test_recall\": float(test_results['eval_recall']),\n",
    "        \"test_f1\": float(test_results['eval_f1'])\n",
    "    },\n",
    "    \"date\": time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "metadata_path = final_model_dir / \"metadata.json\"\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Métadonnées sauvegardées : {metadata_path}\")\n",
    "\n",
    "# Instructions pour télécharger depuis Colab\n",
    "if IN_COLAB:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"IMPORTANT - TÉLÉCHARGEMENT DU MODÈLE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Sur Colab, les fichiers dans /content sont temporaires.\")\n",
    "    print(\"Pour télécharger le modèle entraîné, exécutez cette cellule :\")\n",
    "    print()\n",
    "    print(\"from google.colab import files\")\n",
    "    print(\"import shutil\")\n",
    "    print(f\"shutil.make_archive('camembert_ner_final', 'zip', '{final_model_dir}')\")\n",
    "    print(\"files.download('camembert_ner_final.zip')\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c9782",
   "metadata": {},
   "source": [
    "### 12.2 Sauvegarde du mapping des labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des mappings\n",
    "label_mapping = {\n",
    "    \"label2id\": label2id,\n",
    "    \"id2label\": id2label\n",
    "}\n",
    "\n",
    "label_mapping_path = final_model_dir / \"label_mapping.json\"\n",
    "with open(label_mapping_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(label_mapping, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Mapping des labels sauvegardé : {label_mapping_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da2d81",
   "metadata": {},
   "source": [
    "### 12.3 Téléchargement du modèle (Colab uniquement)\n",
    "\n",
    "⚠️ **IMPORTANT** : Sur Colab, exécutez cette cellule pour télécharger le modèle avant que la session expire !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d7891",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    print(\" Création de l'archive du modèle...\")\n",
    "    \n",
    "    from google.colab import files\n",
    "    import shutil\n",
    "    \n",
    "    # Créer l'archive ZIP\n",
    "    archive_name = 'camembert_ner_final'\n",
    "    shutil.make_archive(archive_name, 'zip', final_model_dir)\n",
    "    \n",
    "    print(f\"✓ Archive créée : {archive_name}.zip (~450 MB)\")\n",
    "    print(\" Téléchargement automatique...\")\n",
    "    \n",
    "    # Télécharger automatiquement\n",
    "    files.download(f'{archive_name}.zip')\n",
    "    \n",
    "    print(\" Modèle téléchargé avec succès !\")\n",
    "else:\n",
    "    print(\"ℹ Cette cellule est uniquement pour Google Colab.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26165ac6",
   "metadata": {},
   "source": [
    "## 13. Test de prédiction sur un exemple\n",
    "\n",
    "### 13.1 Fonction de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c525493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ner(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Prédit les entités nommées dans un texte.\n",
    "    \n",
    "    Args:\n",
    "        text: str - texte à analyser\n",
    "        model: modèle CamemBERT fine-tuné\n",
    "        tokenizer: tokenizer CamemBERT\n",
    "    \n",
    "    Returns:\n",
    "        list de tuples (token, label)\n",
    "    \"\"\"\n",
    "    # Tokenization\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Prédiction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Récupération des prédictions\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)\n",
    "    \n",
    "    # Décodage\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    predicted_labels = [id2label[p.item()] for p in predictions[0]]\n",
    "    \n",
    "    # Filtrage des tokens spéciaux\n",
    "    results = []\n",
    "    for token, label in zip(tokens, predicted_labels):\n",
    "        if token not in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
    "            results.append((token, label))\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Fonction de prédiction définie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe797a6",
   "metadata": {},
   "source": [
    "### 13.2 Exemple de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbff77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texte d'exemple\n",
    "exemple_text = \"La romancière américaine Susan Sontag est née à New York en 1933.\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXEMPLE DE PRÉDICTION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTexte : {exemple_text}\\n\")\n",
    "\n",
    "# Prédiction\n",
    "predictions = predict_ner(exemple_text, model, tokenizer)\n",
    "\n",
    "print(\"Prédictions :\")\n",
    "print(f\"{'Token':<20} | {'Label':<30}\")\n",
    "print(\"-\" * 52)\n",
    "for token, label in predictions:\n",
    "    # Mise en évidence des entités\n",
    "    if label != 'O' and not label.startswith('domain'):\n",
    "        print(f\"{token:<20} | {label:<30} <<<\")\n",
    "    else:\n",
    "        print(f\"{token:<20} | {label:<30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c59d2",
   "metadata": {},
   "source": [
    "## 14. Récapitulatif final\n",
    "\n",
    "### 14.1 Résumé des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff613b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RÉCAPITULATIF FINAL - CAMEMBERT NER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nModèle : {model_checkpoint}\")\n",
    "print(f\"Dataset : MultiCoNER v2 (français)\")\n",
    "print(f\"Nombre d'entités : {len(entity_labels)} types\")\n",
    "print(f\"Nombre total de labels : {num_labels}\")\n",
    "\n",
    "print(f\"\\nDonnées d'entraînement :\")\n",
    "print(f\"  Train : {len(train_sentences):6,} phrases\")\n",
    "print(f\"  Dev   : {len(dev_sentences):6,} phrases\")\n",
    "print(f\"  Test  : {len(test_sentences):6,} phrases\")\n",
    "\n",
    "print(f\"\\nHyperparamètres :\")\n",
    "print(f\"  Epochs       : {training_args.num_train_epochs}\")\n",
    "print(f\"  Batch size   : {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
    "\n",
    "print(f\"\\nRésultats sur DEV :\")\n",
    "print(f\"  Precision : {dev_results['eval_precision']:.4f}\")\n",
    "print(f\"  Recall    : {dev_results['eval_recall']:.4f}\")\n",
    "print(f\"  F1-score  : {dev_results['eval_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nRésultats sur TEST :\")\n",
    "print(f\"  Precision : {test_results['eval_precision']:.4f}\")\n",
    "print(f\"  Recall    : {test_results['eval_recall']:.4f}\")\n",
    "print(f\"  F1-score  : {test_results['eval_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nModèle sauvegardé : {final_model_dir}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a8265",
   "metadata": {},
   "source": [
    "## 15. Conclusion\n",
    "\n",
    "### Points clés\n",
    "\n",
    "**Architecture :**\n",
    "- CamemBERT-base (110M paramètres) pré-entraîné sur 138 GB de texte français\n",
    "- Fine-tuné sur 16,548 phrases annotées du MultiCoNER v2\n",
    "- Tokenization subword avec alignement automatique des labels\n",
    "\n",
    "**Performance :**\n",
    "- Le modèle Transformer surpasse généralement les approches CRF classiques de 10-20% en F1\n",
    "- Capture le contexte bidirectionnel profond\n",
    "- Gère mieux les entités complexes et ambiguës\n",
    "\n",
    "**Utilisation :**\n",
    "- Le modèle est prêt pour la production\n",
    "- Peut être chargé avec `from_pretrained(model_dir)`\n",
    "- Compatible avec l'API Hugging Face\n",
    "\n",
    "### Prochaines étapes possibles\n",
    "\n",
    "1. **Optimisation** : Recherche d'hyperparamètres, plus d'epochs\n",
    "2. **Ensembles** : Combiner CRF + CamemBERT\n",
    "3. **Augmentation** : Techniques d'augmentation de données\n",
    "4. **Déploiement** : API FastAPI, conteneurisation Docker\n",
    "5. **Analyse** : Étude approfondie des erreurs, amélioration ciblée"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
